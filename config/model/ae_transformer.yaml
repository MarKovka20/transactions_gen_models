# early_stopping:
#   _target_: pytorch_lightning.callbacks.EarlyStopping
#   monitor: val_loss
#   mode: min
#   divergence_threshold: 10
checkpoint_metric: val_loss
save_path: saved_models/transformer_churn.pth
trainer_args:
  max_steps: 0
  precision: 16

datamodule_args:
  train_batch_size: 1024
  train_num_workers: 4
  valid_batch_size: 1024
  valid_num_workers: 4

defaults:
 - encoder: transformer
 - module_ae: saved/transformer
