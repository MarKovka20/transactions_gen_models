{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/app/\")\n",
    "\n",
    "from omegaconf import OmegaConf, DictConfig\n",
    "from hydra.utils import instantiate\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from src.preprocessing import preprocess\n",
    "from ptls.data_load.utils import FeatureDict, PaddedBatch, collate_feature_dict\n",
    "from ptls.data_load.datasets import MemoryMapDataset\n",
    "from torch import nn\n",
    "import statistics\n",
    "import torch\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "from functools import partial\n",
    "\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.datasets import SlidingWindowDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = preprocess(OmegaConf.load(\"config/preprocessing/churn_nodup_100.yaml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitRandomizer(FeatureDict):\n",
    "    def __init__(self, part_size: int):\n",
    "        self.part_size = part_size\n",
    "        \n",
    "    def _shuffle(self, parts):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def __call__(self, fd: dict):\n",
    "        seq_len = self.get_seq_len(fd)\n",
    "        idx = torch.arange(seq_len)\n",
    "        parts = list(torch.split(idx, self.part_size))\n",
    "        \n",
    "        parts = self._shuffle(parts)\n",
    "        \n",
    "        return {\n",
    "            k: torch.cat([v[part] for part in parts])\n",
    "            if self.is_seq_feature(k, v) else v\n",
    "            for k, v in fd.items()\n",
    "        }\n",
    "    \n",
    "\n",
    "class Shuffle(SplitRandomizer):\n",
    "    def _shuffle(self, parts):\n",
    "        random.shuffle(parts)\n",
    "        return parts\n",
    "\n",
    "\n",
    "class NeighborSwap(SplitRandomizer):\n",
    "    def __init__(self, part_size: int, p: float):\n",
    "        super().__init__(part_size)\n",
    "        self.p = p\n",
    "    \n",
    "    def _shuffle(self, parts):\n",
    "        for i in range(len(parts) - 1):\n",
    "            if random.random() < self.p:\n",
    "                parts[i], parts[i + 1] = parts[i + 1], parts[i]\n",
    "                \n",
    "        return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderPredictor(LightningModule):\n",
    "    def __init__(self, encoder_cfg: DictConfig, weights_path: str):\n",
    "        super().__init__()\n",
    "        self.encoder: nn.Module = instantiate(encoder_cfg, is_reduce_sequence=True)\n",
    "        self.encoder.load_state_dict(torch.load(weights_path))\n",
    "        \n",
    "    def predict_step(self, batch: PaddedBatch, *args, **kwargs):\n",
    "        return self.encoder(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(\n",
    "    datas: list[dict],\n",
    "    batch_size: int,\n",
    "    encoder_cfg_path: str, \n",
    "    weights_path: str,\n",
    "):\n",
    "    encoder = EncoderPredictor(OmegaConf.load(encoder_cfg_path), weights_path)\n",
    "\n",
    "    dataloaders = [\n",
    "        DataLoader(\n",
    "            MemoryMapDataset(data),\n",
    "            batch_size=batch_size,\n",
    "            collate_fn=collate_feature_dict\n",
    "        )\n",
    "        for data in datas\n",
    "    ]\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        logger=False,\n",
    "        accelerator=\"gpu\",\n",
    "        devices=1\n",
    "    )\n",
    "    \n",
    "    all_preds = trainer.predict(encoder, dataloaders)\n",
    "    return [torch.cat(dataloader_preds)  for dataloader_preds in all_preds]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_sizes = [1, 7, 14, 31, 90, 180, 365]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_sizes_masks = [\n",
    "    torch.BoolTensor([FeatureDict.get_seq_len(row) > 2 * part_size for row in val])\n",
    "    for part_size in part_sizes\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_swap = [[NeighborSwap(part_size, 0.2)(row) for row in val] for part_size in part_sizes]\n",
    "data_shuf = [[Shuffle(part_size)(row) for row in val] for part_size in part_sizes]\n",
    "\n",
    "data_dict = {\n",
    "    \"swap\": [val, *data_swap],\n",
    "    \"shuf\": [val, *data_shuf]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"coles_new\": dict(\n",
    "        encoder_cfg_path=\"config/backbone/encoder/coles_churn_100.yaml\",\n",
    "        weights_path=\"saved_models/coles_churn_100.pth\"\n",
    "    ),\n",
    "    \"coles_old\": dict(\n",
    "        encoder_cfg_path=\"config/backbone/encoder/coles_churn.yaml\",\n",
    "        weights_path=\"coles_best_state_dict.pth\"\n",
    "    ),\n",
    "    \"nlp_new\": dict(\n",
    "        encoder_cfg_path=\"config/backbone/encoder/ae_nlp.yaml\",\n",
    "        weights_path=\"saved_models/ae_nlp.pth\"\n",
    "    ),\n",
    "    \"nlp_old\": dict(\n",
    "        encoder_cfg_path=\"config/backbone/encoder/ae_nlp.yaml\",\n",
    "        weights_path=\"saved_models/ae_nlp_churn_100.pth\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/macro-micro-coles/miniconda/envs/env/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py:92: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "/home/macro-micro-coles/miniconda/envs/env/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/macro-micro-coles/miniconda/envs/env/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, predict_dataloader 1, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/macro-micro-coles/miniconda/envs/env/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, predict_dataloader 2, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/macro-micro-coles/miniconda/envs/env/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, predict_dataloader 3, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/macro-micro-coles/miniconda/envs/env/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, predict_dataloader 4, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/macro-micro-coles/miniconda/envs/env/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, predict_dataloader 5, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/macro-micro-coles/miniconda/envs/env/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, predict_dataloader 6, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/macro-micro-coles/miniconda/envs/env/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, predict_dataloader 7, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd80836941c4eeeb0012f3a0df898d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a302c58d67bd44719882db17957e51be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c434f9940347dfbc73d0dda97235d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df54a5fc710848a8b2552a3a0cc60293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a1c15460ed49ef9b524bca566dd827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee5264eafbe479b9c499b399d5bd8eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "647bbcca95194935b9e501753cc961fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dde4b709da045b4bcdf1bb5da9e76aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_dict = {}\n",
    "\n",
    "for data_name, datas in data_dict.items():\n",
    "    result_dict[data_name] = {}\n",
    "    for model_name, model_args in models.items():\n",
    "        preds = predict(\n",
    "            *datas,\n",
    "            **model_args,\n",
    "            batch_size=32\n",
    "        )\n",
    "        \n",
    "        preds_orig = preds[0]\n",
    "        results = []\n",
    "        for part_sizes_mask, preds_rand in zip(part_sizes_masks, preds[1:]):\n",
    "            orig_masked = preds_orig[part_sizes_mask]\n",
    "            rand_masked = preds_rand[part_sizes_mask]\n",
    "            \n",
    "            results.append(torch.cosine_similarity(orig_masked, rand_masked, dim=-1).mean().item())\n",
    "            \n",
    "        result_dict[data_name][model_name] = results\n",
    "        \n",
    "        del preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coles_new</th>\n",
       "      <th>coles_old</th>\n",
       "      <th>nlp_new</th>\n",
       "      <th>nlp_old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999099</td>\n",
       "      <td>0.999454</td>\n",
       "      <td>0.989854</td>\n",
       "      <td>0.987001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.998969</td>\n",
       "      <td>0.999601</td>\n",
       "      <td>0.979420</td>\n",
       "      <td>0.974817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.999061</td>\n",
       "      <td>0.999668</td>\n",
       "      <td>0.984400</td>\n",
       "      <td>0.980893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.998146</td>\n",
       "      <td>0.999692</td>\n",
       "      <td>0.986323</td>\n",
       "      <td>0.984771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     coles_new  coles_old   nlp_new   nlp_old\n",
       "1     0.999099   0.999454  0.989854  0.987001\n",
       "7     0.998969   0.999601  0.979420  0.974817\n",
       "14    0.999061   0.999668  0.984400  0.980893\n",
       "31    0.998146   0.999692  0.986323  0.984771\n",
       "90    1.000000   1.000000  1.000000  1.000000\n",
       "180        NaN        NaN       NaN       NaN\n",
       "365        NaN        NaN       NaN       NaN"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result_dict[\"swap\"], index=part_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coles_new</th>\n",
       "      <th>coles_old</th>\n",
       "      <th>nlp_new</th>\n",
       "      <th>nlp_old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.988675</td>\n",
       "      <td>0.995116</td>\n",
       "      <td>0.909995</td>\n",
       "      <td>0.898983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.991332</td>\n",
       "      <td>0.997718</td>\n",
       "      <td>0.918375</td>\n",
       "      <td>0.908441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.991780</td>\n",
       "      <td>0.998080</td>\n",
       "      <td>0.927512</td>\n",
       "      <td>0.920640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.992884</td>\n",
       "      <td>0.998776</td>\n",
       "      <td>0.946774</td>\n",
       "      <td>0.941986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.988638</td>\n",
       "      <td>0.997104</td>\n",
       "      <td>0.961812</td>\n",
       "      <td>0.964229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     coles_new  coles_old   nlp_new   nlp_old\n",
       "1     0.988675   0.995116  0.909995  0.898983\n",
       "7     0.991332   0.997718  0.918375  0.908441\n",
       "14    0.991780   0.998080  0.927512  0.920640\n",
       "31    0.992884   0.998776  0.946774  0.941986\n",
       "90    0.988638   0.997104  0.961812  0.964229\n",
       "180        NaN        NaN       NaN       NaN\n",
       "365        NaN        NaN       NaN       NaN"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result_dict[\"shuf\"], index=part_sizes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
