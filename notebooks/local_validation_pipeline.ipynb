{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 1,
         "id": "523b8323",
         "metadata": {},
         "outputs": [],
         "source": [
            "import warnings\n",
            "warnings.filterwarnings(\"ignore\")\n",
            "\n",
            "import os\n",
            "import sys\n",
            "\n",
            "dir2 = os.path.abspath('')\n",
            "dir1 = os.path.dirname(dir2)\n",
            "if not dir1 in sys.path:\n",
            "    sys.path.append(dir1)\n",
            "\n",
            "os.chdir('..')\n",
            "\n",
            "%load_ext autoreload\n",
            "%autoreload"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "id": "ec405c66",
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "comet_ml is installed but `COMET_API_KEY` is not set.\n"
               ]
            }
         ],
         "source": [
            "from pathlib import Path\n",
            "\n",
            "import pandas as pd\n",
            "\n",
            "import torch\n",
            "\n",
            "from hydra import initialize, compose\n",
            "from hydra.utils import instantiate\n",
            "\n",
            "from ptls.frames import PtlsDataModule\n",
            "from ptls.frames.coles import ColesDataset\n",
            "\n",
            "from ptls.data_load.datasets import MemoryMapDataset\n",
            "from ptls.data_load.iterable_processing import SeqLenFilter\n",
            "\n",
            "from pytorch_lightning import Trainer, seed_everything\n",
            "from pytorch_lightning.loggers import TensorBoardLogger, CometLogger\n",
            "\n",
            "from sklearn.model_selection import train_test_split\n",
            "\n",
            "from src.local_validation import LocalValidationModel\n",
            "\n",
            "from src.utils.logging_utils import get_logger\n",
            "from src.preprocessing import preprocess\n"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "2c0ee347",
         "metadata": {},
         "source": [
            "## Read data"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "id": "10c11f29",
         "metadata": {},
         "outputs": [],
         "source": [
            "DATASET = \"churn\"\n",
            "\n",
            "with initialize(config_path=\"../config\", version_base=None):\n",
            "    cfg = compose(config_name=\"config_\" + DATASET)\n",
            "    \n",
            "cfg_preprop = cfg[\"preprocessing\"]\n",
            "cfg_dataset = cfg[\"dataset\"]\n",
            "cfg_model = cfg[\"model\"]\n",
            "cfg_validation = cfg[\"validation\"]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "id": "4d1fc50a",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<div>\n",
                     "<style scoped>\n",
                     "    .dataframe tbody tr th:only-of-type {\n",
                     "        vertical-align: middle;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe tbody tr th {\n",
                     "        vertical-align: top;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe thead th {\n",
                     "        text-align: right;\n",
                     "    }\n",
                     "</style>\n",
                     "<table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     "    <tr style=\"text-align: right;\">\n",
                     "      <th></th>\n",
                     "      <th>user_id</th>\n",
                     "      <th>mcc_code</th>\n",
                     "      <th>timestamp</th>\n",
                     "      <th>amount</th>\n",
                     "      <th>global_target</th>\n",
                     "      <th>holiday_target</th>\n",
                     "      <th>weekend_target</th>\n",
                     "      <th>churn_target</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <th>0</th>\n",
                     "      <td>0</td>\n",
                     "      <td>147</td>\n",
                     "      <td>2017-10-21 00:00:00</td>\n",
                     "      <td>5023.0</td>\n",
                     "      <td>0</td>\n",
                     "      <td>0</td>\n",
                     "      <td>1</td>\n",
                     "      <td>0</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>1</th>\n",
                     "      <td>0</td>\n",
                     "      <td>244</td>\n",
                     "      <td>2017-10-12 12:24:07</td>\n",
                     "      <td>20000.0</td>\n",
                     "      <td>0</td>\n",
                     "      <td>0</td>\n",
                     "      <td>0</td>\n",
                     "      <td>0</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>2</th>\n",
                     "      <td>0</td>\n",
                     "      <td>204</td>\n",
                     "      <td>2017-12-05 00:00:00</td>\n",
                     "      <td>767.0</td>\n",
                     "      <td>0</td>\n",
                     "      <td>0</td>\n",
                     "      <td>0</td>\n",
                     "      <td>0</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>3</th>\n",
                     "      <td>0</td>\n",
                     "      <td>158</td>\n",
                     "      <td>2017-10-21 00:00:00</td>\n",
                     "      <td>2031.0</td>\n",
                     "      <td>0</td>\n",
                     "      <td>0</td>\n",
                     "      <td>1</td>\n",
                     "      <td>0</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>4</th>\n",
                     "      <td>0</td>\n",
                     "      <td>245</td>\n",
                     "      <td>2017-10-24 13:14:24</td>\n",
                     "      <td>36562.0</td>\n",
                     "      <td>0</td>\n",
                     "      <td>0</td>\n",
                     "      <td>0</td>\n",
                     "      <td>0</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>...</th>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>490508</th>\n",
                     "      <td>10215</td>\n",
                     "      <td>102</td>\n",
                     "      <td>2016-12-17 00:00:00</td>\n",
                     "      <td>2110.9</td>\n",
                     "      <td>0</td>\n",
                     "      <td>0</td>\n",
                     "      <td>1</td>\n",
                     "      <td>0</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>490509</th>\n",
                     "      <td>10215</td>\n",
                     "      <td>158</td>\n",
                     "      <td>2016-12-16 00:00:00</td>\n",
                     "      <td>31.0</td>\n",
                     "      <td>0</td>\n",
                     "      <td>0</td>\n",
                     "      <td>0</td>\n",
                     "      <td>0</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>490510</th>\n",
                     "      <td>10215</td>\n",
                     "      <td>158</td>\n",
                     "      <td>2016-12-06 00:00:00</td>\n",
                     "      <td>182.0</td>\n",
                     "      <td>0</td>\n",
                     "      <td>0</td>\n",
                     "      <td>0</td>\n",
                     "      <td>0</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>490511</th>\n",
                     "      <td>10215</td>\n",
                     "      <td>244</td>\n",
                     "      <td>2016-12-06 13:39:49</td>\n",
                     "      <td>5000.0</td>\n",
                     "      <td>0</td>\n",
                     "      <td>0</td>\n",
                     "      <td>0</td>\n",
                     "      <td>0</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>490512</th>\n",
                     "      <td>10215</td>\n",
                     "      <td>244</td>\n",
                     "      <td>2016-12-06 13:42:19</td>\n",
                     "      <td>30000.0</td>\n",
                     "      <td>0</td>\n",
                     "      <td>0</td>\n",
                     "      <td>0</td>\n",
                     "      <td>0</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table>\n",
                     "<p>490513 rows Ã— 8 columns</p>\n",
                     "</div>"
                  ],
                  "text/plain": [
                     "        user_id  mcc_code           timestamp   amount  global_target  \\\n",
                     "0             0       147 2017-10-21 00:00:00   5023.0              0   \n",
                     "1             0       244 2017-10-12 12:24:07  20000.0              0   \n",
                     "2             0       204 2017-12-05 00:00:00    767.0              0   \n",
                     "3             0       158 2017-10-21 00:00:00   2031.0              0   \n",
                     "4             0       245 2017-10-24 13:14:24  36562.0              0   \n",
                     "...         ...       ...                 ...      ...            ...   \n",
                     "490508    10215       102 2016-12-17 00:00:00   2110.9              0   \n",
                     "490509    10215       158 2016-12-16 00:00:00     31.0              0   \n",
                     "490510    10215       158 2016-12-06 00:00:00    182.0              0   \n",
                     "490511    10215       244 2016-12-06 13:39:49   5000.0              0   \n",
                     "490512    10215       244 2016-12-06 13:42:19  30000.0              0   \n",
                     "\n",
                     "        holiday_target  weekend_target  churn_target  \n",
                     "0                    0               1             0  \n",
                     "1                    0               0             0  \n",
                     "2                    0               0             0  \n",
                     "3                    0               1             0  \n",
                     "4                    0               0             0  \n",
                     "...                ...             ...           ...  \n",
                     "490508               0               1             0  \n",
                     "490509               0               0             0  \n",
                     "490510               0               0             0  \n",
                     "490511               0               0             0  \n",
                     "490512               0               0             0  \n",
                     "\n",
                     "[490513 rows x 8 columns]"
                  ]
               },
               "execution_count": 4,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "df = pd.read_parquet(Path(cfg[\"preprocessing\"][\"source\"]))\n",
            "df"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "72f7ea26",
         "metadata": {},
         "source": [
            "## Preprocess and split data"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "id": "2c55828a",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "[Memory]0.0s, 0.0min    : Loading _preprocess...\n",
                  "__________________________________________preprocess cache loaded - 5.7s, 0.1min\n"
               ]
            }
         ],
         "source": [
            "train, val, test = preprocess(cfg_preprop)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "a8198cc0",
         "metadata": {},
         "source": [
            "## Init backbone model and load weights"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "id": "3d4882a4",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "<All keys matched successfully>"
                  ]
               },
               "execution_count": 6,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "sequence_encoder = instantiate(cfg_validation[\"sequence_encoder\"])\n",
            "sequence_encoder.load_state_dict(torch.load(cfg_validation[\"path_to_state_dict\"]))"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "6487025b",
         "metadata": {},
         "source": [
            "# Validation"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "3deb33fd",
         "metadata": {},
         "source": [
            "## Use datasets with no splits for the new validation procedure"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "id": "2b836e1a",
         "metadata": {},
         "outputs": [],
         "source": [
            "data_train = MemoryMapDataset(train, [SeqLenFilter(cfg_validation[\"model\"][\"seq_len\"])])\n",
            "data_val = MemoryMapDataset(val, [SeqLenFilter(cfg_validation[\"model\"][\"seq_len\"])])\n",
            "data_test = MemoryMapDataset(test, [SeqLenFilter(cfg_validation[\"model\"][\"seq_len\"])])\n",
            "\n",
            "train_dataset: ColesDataset = instantiate(cfg_validation[\"dataset\"], data=data_train)\n",
            "val_dataset: ColesDataset = instantiate(cfg_validation[\"dataset\"], data=data_val)\n",
            "test_dataset: ColesDataset = instantiate(cfg_validation[\"dataset\"], data=data_test)\n",
            "\n",
            "datamodule: PtlsDataModule = instantiate(\n",
            "    cfg_validation[\"datamodule\"],\n",
            "    train_data=train_dataset,\n",
            "    valid_data=val_dataset,\n",
            "    test_data=test_dataset,\n",
            ")"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "bf0a7d3a",
         "metadata": {},
         "source": [
            "# New validation model"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "id": "6342d25e",
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Global seed set to 42\n"
               ]
            }
         ],
         "source": [
            "seed_everything(42)\n",
            "\n",
            "\"\"\"\n",
            "'val_mode' options:\n",
            "    * 'donwstream' - using local targets (e.g. 'churn_target' or 'default_target')\n",
            "    * 'return_time' - predicting return time (COTIC-style) - NOT READY YET\n",
            "    * 'event_type' - predicting next event type (COTIC-style)\n",
            "\"\"\"\n",
            "\n",
            "valid_model: LocalValidationModel = instantiate(\n",
            "    cfg_validation[\"model\"],\n",
            "    backbone=sequence_encoder \n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "id": "3b634e6a",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "inputs event time: torch.Size([4, 357])\n",
                  "preds: torch.Size([4, 326, 1])\n",
                  "mask: torch.Size([4, 326])\n",
                  "target: torch.Size([4, 326])\n"
               ]
            }
         ],
         "source": [
            "batch, labels = next(iter(datamodule.train_dataloader()))\n",
            "\n",
            "print(\"inputs event time:\", batch.payload[\"event_time\"].shape)\n",
            "\n",
            "preds, mask = valid_model(batch)\n",
            "target = valid_model._get_validation_labels(batch)\n",
            "\n",
            "print(\"preds:\", preds.shape)\n",
            "print(\"mask:\", mask.shape)\n",
            "print(\"target:\", target.shape)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "c0e9a803",
         "metadata": {
            "scrolled": false
         },
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "GPU available: True, used: True\n",
                  "TPU available: False, using: 0 TPU cores\n",
                  "IPU available: False, using: 0 IPUs\n",
                  "HPU available: False, using: 0 HPUs\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
                  "\n",
                  "  | Name      | Type             | Params\n",
                  "-----------------------------------------------\n",
                  "0 | backbone  | RnnSeqEncoder    | 4.3 M \n",
                  "1 | pred_head | Sequential       | 44.2 K\n",
                  "2 | loss      | CrossEntropyLoss | 0     \n",
                  "-----------------------------------------------\n",
                  "44.2 K    Trainable params\n",
                  "4.3 M     Non-trainable params\n",
                  "4.4 M     Total params\n",
                  "17.434    Total estimated model params size (MB)\n"
               ]
            },
            {
               "data": {
                  "application/vnd.jupyter.widget-view+json": {
                     "model_id": "caa5d273a97b47c6883844c9404a574b",
                     "version_major": 2,
                     "version_minor": 0
                  },
                  "text/plain": [
                     "Sanity Checking: 0it [00:00, ?it/s]"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "ename": "RuntimeError",
               "evalue": "expected scalar type Long but found Double",
               "output_type": "error",
               "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
                  "\u001b[1;32m/app/notebooks/local_validation_pipeline.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f62617a61726f76612d636f6c6573222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d69646173227d7d/app/notebooks/local_validation_pipeline.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#comet_logger = CometLogger(\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f62617a61726f76612d636f6c6573222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d69646173227d7d/app/notebooks/local_validation_pipeline.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m#    api_key=\"agnHNC2vEt7tOxnnxT4LzYf7Y\",\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f62617a61726f76612d636f6c6573222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d69646173227d7d/app/notebooks/local_validation_pipeline.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#    project_name=\"macro-micro-coles\",\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f62617a61726f76612d636f6c6573222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d69646173227d7d/app/notebooks/local_validation_pipeline.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m#    display_summary_level=0\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f62617a61726f76612d636f6c6573222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d69646173227d7d/app/notebooks/local_validation_pipeline.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m#)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f62617a61726f76612d636f6c6573222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d69646173227d7d/app/notebooks/local_validation_pipeline.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m val_trainer: Trainer \u001b[39m=\u001b[39m instantiate(cfg_validation[\u001b[39m\"\u001b[39m\u001b[39mtrainer\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f62617a61726f76612d636f6c6573222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d69646173227d7d/app/notebooks/local_validation_pipeline.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m val_trainer\u001b[39m.\u001b[39;49mfit(valid_model, datamodule)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f62617a61726f76612d636f6c6573222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d69646173227d7d/app/notebooks/local_validation_pipeline.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m val_trainer\u001b[39m.\u001b[39mtest(valid_model, datamodule)\n",
                  "File \u001b[0;32m~/miniconda/envs/env/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:770\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[39mRuns the full optimization routine.\u001b[39;00m\n\u001b[1;32m    753\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[39m    datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\u001b[39;00m\n\u001b[1;32m    768\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    769\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 770\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    771\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    772\u001b[0m )\n",
                  "File \u001b[0;32m~/miniconda/envs/env/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:723\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    722\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 723\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    724\u001b[0m \u001b[39m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m exception:\n",
                  "File \u001b[0;32m~/miniconda/envs/env/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:811\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    807\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    808\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_ckpt_path(\n\u001b[1;32m    809\u001b[0m     ckpt_path, model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    810\u001b[0m )\n\u001b[0;32m--> 811\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[1;32m    813\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    814\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
                  "File \u001b[0;32m~/miniconda/envs/env/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1236\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1232\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mrestore_training_state()\n\u001b[1;32m   1234\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mresume_end()\n\u001b[0;32m-> 1236\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m   1238\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1239\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_teardown()\n",
                  "File \u001b[0;32m~/miniconda/envs/env/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1323\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1321\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[1;32m   1322\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_predict()\n\u001b[0;32m-> 1323\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_train()\n",
                  "File \u001b[0;32m~/miniconda/envs/env/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1345\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pre_training_routine()\n\u001b[1;32m   1344\u001b[0m \u001b[39mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1345\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_sanity_check()\n\u001b[1;32m   1347\u001b[0m \u001b[39m# enable train mode\u001b[39;00m\n\u001b[1;32m   1348\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain()\n",
                  "File \u001b[0;32m~/miniconda/envs/env/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1413\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1411\u001b[0m \u001b[39m# run eval step\u001b[39;00m\n\u001b[1;32m   1412\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m-> 1413\u001b[0m     val_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m   1415\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_end\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1417\u001b[0m \u001b[39m# reset logger connector\u001b[39;00m\n",
                  "File \u001b[0;32m~/miniconda/envs/env/lib/python3.9/site-packages/pytorch_lightning/loops/base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 204\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    205\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
                  "File \u001b[0;32m~/miniconda/envs/env/lib/python3.9/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py:155\u001b[0m, in \u001b[0;36mEvaluationLoop.advance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_dataloaders \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    154\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mdataloader_idx\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m dataloader_idx\n\u001b[0;32m--> 155\u001b[0m dl_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher, dl_max_batches, kwargs)\n\u001b[1;32m    157\u001b[0m \u001b[39m# store batch level output per dataloader\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs\u001b[39m.\u001b[39mappend(dl_outputs)\n",
                  "File \u001b[0;32m~/miniconda/envs/env/lib/python3.9/site-packages/pytorch_lightning/loops/base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 204\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    205\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
                  "File \u001b[0;32m~/miniconda/envs/env/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:128\u001b[0m, in \u001b[0;36mEvaluationEpochLoop.advance\u001b[0;34m(self, data_fetcher, dl_max_batches, kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_started()\n\u001b[1;32m    127\u001b[0m \u001b[39m# lightning module methods\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_step(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    129\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluation_step_end(output)\n\u001b[1;32m    131\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n",
                  "File \u001b[0;32m~/miniconda/envs/env/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:226\u001b[0m, in \u001b[0;36mEvaluationEpochLoop._evaluation_step\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39m_call_strategy_hook(\u001b[39m\"\u001b[39m\u001b[39mtest_step\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39mkwargs\u001b[39m.\u001b[39mvalues())\n\u001b[1;32m    225\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 226\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49m_call_strategy_hook(\u001b[39m\"\u001b[39;49m\u001b[39mvalidation_step\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mvalues())\n\u001b[1;32m    228\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
                  "File \u001b[0;32m~/miniconda/envs/env/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1765\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[0;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1762\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1764\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1765\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1767\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m   1768\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
                  "File \u001b[0;32m~/miniconda/envs/env/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py:344\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"The actual validation step.\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \n\u001b[1;32m    341\u001b[0m \u001b[39mSee :meth:`~pytorch_lightning.core.lightning.LightningModule.validation_step` for more details\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mval_step_context():\n\u001b[0;32m--> 344\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mvalidation_step(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
                  "File \u001b[0;32m/app/src/local_validation/local_validation_model.py:373\u001b[0m, in \u001b[0;36mLocalValidationModel.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    371\u001b[0m     preds, target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_type_target_and_preds(preds, target)\n\u001b[0;32m--> 373\u001b[0m     val_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss(preds, target)\u001b[39m.\u001b[39mmean()\n\u001b[1;32m    375\u001b[0m     metric_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39macc\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    376\u001b[0m     metric \u001b[39m=\u001b[39m Accuracy(\n\u001b[1;32m    377\u001b[0m         task\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    378\u001b[0m         num_classes\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_types,\n\u001b[1;32m    379\u001b[0m         ignore_index\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmcc_padd_value,\n\u001b[1;32m    380\u001b[0m     )\u001b[39m.\u001b[39mto(preds\u001b[39m.\u001b[39mdevice)(preds, target)\n",
                  "File \u001b[0;32m~/miniconda/envs/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
                  "File \u001b[0;32m~/miniconda/envs/env/lib/python3.9/site-packages/torch/nn/modules/loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m-> 1174\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m   1175\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[1;32m   1176\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
                  "File \u001b[0;32m~/miniconda/envs/env/lib/python3.9/site-packages/torch/nn/functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3028\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3029\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
                  "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Long but found Double"
               ]
            }
         ],
         "source": [
            "val_trainer: Trainer = instantiate(cfg_validation[\"trainer\"])\n",
            "    \n",
            "val_trainer.fit(valid_model, datamodule)\n",
            "val_trainer.test(valid_model, datamodule)"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3 (ipykernel)",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.9.16"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 5
}