{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "dir2 = os.path.abspath('')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path:\n",
    "    sys.path.append(dir1)\n",
    "\n",
    "os.chdir('..')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import initialize, compose\n",
    "from hydra.utils import instantiate\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src.preprocessing import preprocess\n",
    "from src.pooling import PoolingModel\n",
    "\n",
    "from src.global_validation.global_validation_pipeline import embed_data, eval_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(config_path=\"../config\", version_base=None):\n",
    "    cfg = compose(config_name=\"config_validation_churn\")\n",
    "\n",
    "cfg_preprop = cfg[\"preprocessing\"]\n",
    "cfg_validation = cfg[\"validation\"][\"global_target\"]\n",
    "cfg_encoder = cfg[\"backbone\"][\"encoder\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_encoder[\"trx_encoder\"][\"embeddings\"][\"mcc_code\"][\"in\"] = 345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = preprocess(cfg_preprop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_name = \"coles_churn\"\n",
    "sequence_encoder = instantiate(cfg_encoder, is_reduce_sequence=True)\n",
    "sequence_encoder.load_state_dict(torch.load(f\"saved_models/{encoder_name}.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_encoder.seq_encoder.rnn.hidden_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 590/4000 [01:13<07:04,  8.04it/s]\n",
      "100%|██████████| 4210/4210 [00:09<00:00, 467.13it/s]\n"
     ]
    }
   ],
   "source": [
    "pooling_model = PoolingModel(train_data = train,\n",
    "        backbone = sequence_encoder,\n",
    "        backbone_embd_size = sequence_encoder.seq_encoder.rnn.hidden_size,\n",
    "        max_users_in_train_dataloader=500,\n",
    "        pooling_type = \"attention\",\n",
    "        min_seq_length = 15,\n",
    "        max_seq_length = 100,\n",
    "        max_embs_per_user = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get representations of sequences from train + val part\n",
    "embeddings, targets = embed_data(pooling_model, train + val, **cfg_validation[\"embed_data\"])\n",
    "N = len(embeddings)\n",
    "indices = np.arange(N)\n",
    "\n",
    "# get representations of sequences from test part\n",
    "embeddings_test, targets_test = embed_data(\n",
    "    pooling_model,\n",
    "    test,\n",
    "    **cfg_validation[\"embed_data\"]\n",
    ")\n",
    "\n",
    "results = []\n",
    "for i in range(cfg_validation[\"n_runs\"]):\n",
    "\n",
    "    # bootstrap sample\n",
    "    bootstrap_inds = np.random.choice(indices, size=N, replace=True)\n",
    "    embeddings_train, targets_train = embeddings[bootstrap_inds], targets[bootstrap_inds]\n",
    "\n",
    "    # evaluate trained model\n",
    "    metrics = eval_embeddings(\n",
    "        embeddings_train,\n",
    "        targets_train,\n",
    "        embeddings_test,\n",
    "        targets_test,\n",
    "        cfg_validation[\"model\"]\n",
    "    )\n",
    "\n",
    "    results.append(metrics)\n",
    "\n",
    "res = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUROC</th>\n",
       "      <th>PR-AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.751386</td>\n",
       "      <td>0.801715</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.743633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.762242</td>\n",
       "      <td>0.805629</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.752108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.742452</td>\n",
       "      <td>0.786899</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.735441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.741768</td>\n",
       "      <td>0.789662</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.749141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.753700</td>\n",
       "      <td>0.803366</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.747941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.757629</td>\n",
       "      <td>0.800113</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.766892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.752527</td>\n",
       "      <td>0.794137</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.739726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.744914</td>\n",
       "      <td>0.801099</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.733108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.737432</td>\n",
       "      <td>0.789842</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.726962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.753684</td>\n",
       "      <td>0.790736</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.751701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AUROC    PR-AUC  Accuracy   F1Score\n",
       "0  0.751386  0.801715     0.698  0.743633\n",
       "1  0.762242  0.805629     0.706  0.752108\n",
       "2  0.742452  0.786899     0.682  0.735441\n",
       "3  0.741768  0.789662     0.708  0.749141\n",
       "4  0.753700  0.803366     0.694  0.747941\n",
       "5  0.757629  0.800113     0.724  0.766892\n",
       "6  0.752527  0.794137     0.696  0.739726\n",
       "7  0.744914  0.801099     0.684  0.733108\n",
       "8  0.737432  0.789842     0.680  0.726962\n",
       "9  0.753684  0.790736     0.708  0.751701"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUROC</th>\n",
       "      <th>PR-AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.749773</td>\n",
       "      <td>0.796320</td>\n",
       "      <td>0.698000</td>\n",
       "      <td>0.744665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.007829</td>\n",
       "      <td>0.006779</td>\n",
       "      <td>0.013888</td>\n",
       "      <td>0.011485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         AUROC    PR-AUC  Accuracy   F1Score\n",
       "mean  0.749773  0.796320  0.698000  0.744665\n",
       "std   0.007829  0.006779  0.013888  0.011485"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.agg([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling_model.pooling_type = \"mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, targets = embed_data(pooling_model, train + val, **cfg_validation[\"embed_data\"])\n",
    "N = len(embeddings)\n",
    "indices = np.arange(N)\n",
    "\n",
    "embeddings_test, targets_test = embed_data(\n",
    "    pooling_model,\n",
    "    test,\n",
    "    **cfg_validation[\"embed_data\"]\n",
    ")\n",
    "\n",
    "results = []\n",
    "for i in range(cfg_validation[\"n_runs\"]):\n",
    "\n",
    "    bootstrap_inds = np.random.choice(indices, size=N, replace=True)\n",
    "    embeddings_train, targets_train = embeddings[bootstrap_inds], targets[bootstrap_inds]\n",
    "\n",
    "    metrics = eval_embeddings(\n",
    "        embeddings_train,\n",
    "        targets_train,\n",
    "        embeddings_test,\n",
    "        targets_test,\n",
    "        cfg_validation[\"model\"]\n",
    "    )\n",
    "\n",
    "    results.append(metrics)\n",
    "\n",
    "res = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUROC</th>\n",
       "      <th>PR-AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.759993</td>\n",
       "      <td>0.807043</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.764785</td>\n",
       "      <td>0.821024</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.747885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.763921</td>\n",
       "      <td>0.819725</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.744898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.762683</td>\n",
       "      <td>0.809550</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.744574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.778984</td>\n",
       "      <td>0.830819</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.752981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.755820</td>\n",
       "      <td>0.804151</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.729412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.766465</td>\n",
       "      <td>0.815010</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.753333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.773001</td>\n",
       "      <td>0.831362</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.750419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.756537</td>\n",
       "      <td>0.803116</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.732441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.760629</td>\n",
       "      <td>0.813666</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.731544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AUROC    PR-AUC  Accuracy   F1Score\n",
       "0  0.759993  0.807043     0.694  0.742857\n",
       "1  0.764785  0.821024     0.702  0.747885\n",
       "2  0.763921  0.819725     0.700  0.744898\n",
       "3  0.762683  0.809550     0.694  0.744574\n",
       "4  0.778984  0.830819     0.710  0.752981\n",
       "5  0.755820  0.804151     0.678  0.729412\n",
       "6  0.766465  0.815010     0.704  0.753333\n",
       "7  0.773001  0.831362     0.702  0.750419\n",
       "8  0.756537  0.803116     0.680  0.732441\n",
       "9  0.760629  0.813666     0.680  0.731544"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUROC</th>\n",
       "      <th>PR-AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.764282</td>\n",
       "      <td>0.815547</td>\n",
       "      <td>0.694400</td>\n",
       "      <td>0.743034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.007174</td>\n",
       "      <td>0.010150</td>\n",
       "      <td>0.011384</td>\n",
       "      <td>0.008937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         AUROC    PR-AUC  Accuracy   F1Score\n",
       "mean  0.764282  0.815547  0.694400  0.743034\n",
       "std   0.007174  0.010150  0.011384  0.008937"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.agg([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling_model.pooling_type = \"max\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, targets = embed_data(pooling_model, train + val, **cfg_validation[\"embed_data\"])\n",
    "N = len(embeddings)\n",
    "indices = np.arange(N)\n",
    "\n",
    "embeddings_test, targets_test = embed_data(\n",
    "    pooling_model,\n",
    "    test,\n",
    "    **cfg_validation[\"embed_data\"]\n",
    ")\n",
    "\n",
    "results = []\n",
    "for i in range(cfg_validation[\"n_runs\"]):\n",
    "\n",
    "    bootstrap_inds = np.random.choice(indices, size=N, replace=True)\n",
    "    embeddings_train, targets_train = embeddings[bootstrap_inds], targets[bootstrap_inds]\n",
    "\n",
    "    metrics = eval_embeddings(\n",
    "        embeddings_train,\n",
    "        targets_train,\n",
    "        embeddings_test,\n",
    "        targets_test,\n",
    "        cfg_validation[\"model\"]\n",
    "    )\n",
    "\n",
    "    results.append(metrics)\n",
    "\n",
    "res = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUROC</th>\n",
       "      <th>PR-AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.785065</td>\n",
       "      <td>0.833013</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.771523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.767231</td>\n",
       "      <td>0.819703</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.752508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.766579</td>\n",
       "      <td>0.824111</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.745363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.775773</td>\n",
       "      <td>0.827008</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.755932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.780386</td>\n",
       "      <td>0.837252</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.743243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.760221</td>\n",
       "      <td>0.818162</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.723260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.763432</td>\n",
       "      <td>0.821092</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.751269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.772121</td>\n",
       "      <td>0.816919</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.747440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.771029</td>\n",
       "      <td>0.824572</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.734134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.759324</td>\n",
       "      <td>0.809436</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.735043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AUROC    PR-AUC  Accuracy   F1Score\n",
       "0  0.785065  0.833013     0.724  0.771523\n",
       "1  0.767231  0.819703     0.704  0.752508\n",
       "2  0.766579  0.824111     0.698  0.745363\n",
       "3  0.775773  0.827008     0.712  0.755932\n",
       "4  0.780386  0.837252     0.696  0.743243\n",
       "5  0.760221  0.818162     0.674  0.723260\n",
       "6  0.763432  0.821092     0.706  0.751269\n",
       "7  0.772121  0.816919     0.704  0.747440\n",
       "8  0.771029  0.824572     0.690  0.734134\n",
       "9  0.759324  0.809436     0.690  0.735043"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUROC</th>\n",
       "      <th>PR-AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.770116</td>\n",
       "      <td>0.823127</td>\n",
       "      <td>0.699800</td>\n",
       "      <td>0.745972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.008470</td>\n",
       "      <td>0.008041</td>\n",
       "      <td>0.013677</td>\n",
       "      <td>0.013368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         AUROC    PR-AUC  Accuracy   F1Score\n",
       "mean  0.770116  0.823127  0.699800  0.745972\n",
       "std   0.008470  0.008041  0.013677  0.013368"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.agg([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, targets = embed_data(sequence_encoder, train + val, **cfg_validation[\"embed_data\"])\n",
    "N = len(embeddings)\n",
    "indices = np.arange(N)\n",
    "\n",
    "embeddings_test, targets_test = embed_data(\n",
    "    sequence_encoder,\n",
    "    test,\n",
    "    **cfg_validation[\"embed_data\"]\n",
    ")\n",
    "\n",
    "results = []\n",
    "for i in range(cfg_validation[\"n_runs\"]):\n",
    "\n",
    "    bootstrap_inds = np.random.choice(indices, size=N, replace=True)\n",
    "    embeddings_train, targets_train = embeddings[bootstrap_inds], targets[bootstrap_inds]\n",
    "\n",
    "    metrics = eval_embeddings(\n",
    "        embeddings_train,\n",
    "        targets_train,\n",
    "        embeddings_test,\n",
    "        targets_test,\n",
    "        cfg_validation[\"model\"]\n",
    "    )\n",
    "\n",
    "    results.append(metrics)\n",
    "\n",
    "res = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUROC</th>\n",
       "      <th>PR-AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.733038</td>\n",
       "      <td>0.770301</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.738095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.738483</td>\n",
       "      <td>0.797514</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.712095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.712075</td>\n",
       "      <td>0.773563</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.712605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.737790</td>\n",
       "      <td>0.787723</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.745033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.729020</td>\n",
       "      <td>0.778552</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.715474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.725890</td>\n",
       "      <td>0.775334</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.716007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.740040</td>\n",
       "      <td>0.773981</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.738462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.734163</td>\n",
       "      <td>0.778188</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.726027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.739600</td>\n",
       "      <td>0.786991</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.744140</td>\n",
       "      <td>0.792434</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.728499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AUROC    PR-AUC  Accuracy   F1Score\n",
       "0  0.733038  0.770301     0.692  0.738095\n",
       "1  0.738483  0.797514     0.662  0.712095\n",
       "2  0.712075  0.773563     0.658  0.712605\n",
       "3  0.737790  0.787723     0.692  0.745033\n",
       "4  0.729020  0.778552     0.658  0.715474\n",
       "5  0.725890  0.775334     0.670  0.716007\n",
       "6  0.740040  0.773981     0.694  0.738462\n",
       "7  0.734163  0.778188     0.680  0.726027\n",
       "8  0.739600  0.786991     0.680  0.733333\n",
       "9  0.744140  0.792434     0.678  0.728499"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUROC</th>\n",
       "      <th>PR-AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.733424</td>\n",
       "      <td>0.781458</td>\n",
       "      <td>0.676400</td>\n",
       "      <td>0.726563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.009274</td>\n",
       "      <td>0.009113</td>\n",
       "      <td>0.013946</td>\n",
       "      <td>0.012038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         AUROC    PR-AUC  Accuracy   F1Score\n",
       "mean  0.733424  0.781458  0.676400  0.726563\n",
       "std   0.009274  0.009113  0.013946  0.012038"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.agg([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learnable attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling_model.change_pooling_type(\"learnable_attention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with initialize(config_path=\"../config/model\", version_base=None):\n",
    "#     cfg_model = compose(config_name=\"coles_churn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.coles import CustomColesDataset, CustomCoLES\n",
    "\n",
    "# from pytorch_lightning import Trainer\n",
    "# from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "# from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "# from ptls.frames import PtlsDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: CustomCoLES = instantiate(cfg_model[\"model\"],\n",
    "#                                  sequence_encoder = pooling_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialize original CoLES datasest - for CoLES training\n",
    "# train_data: CustomColesDataset = instantiate(cfg_model[\"dataset\"], data=train)\n",
    "# val_data: CustomColesDataset = instantiate(cfg_model[\"dataset\"], data=val)\n",
    "    \n",
    "# train_datamodule: PtlsDataModule = instantiate(\n",
    "#     cfg_model[\"datamodule\"],\n",
    "#     train_data=train_data,\n",
    "#     valid_data=val_data\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_checkpoint: ModelCheckpoint = instantiate(\n",
    "#     cfg_model[\"trainer_coles\"][\"checkpoint_callback\"],\n",
    "#     monitor=model.metric_name,\n",
    "#     mode=\"max\"\n",
    "# )\n",
    "    \n",
    "# early_stopping: EarlyStopping = instantiate(\n",
    "#     cfg_model[\"trainer_coles\"][\"early_stopping\"],\n",
    "#     monitor=model.metric_name,\n",
    "#     mode=\"max\"\n",
    "# )\n",
    "    \n",
    "# logger: TensorBoardLogger = instantiate(cfg_model[\"trainer_coles\"][\"logger\"])\n",
    "    \n",
    "# trainer: Trainer = instantiate(\n",
    "#     cfg_model[\"trainer_coles\"][\"trainer\"],\n",
    "#     callbacks=[model_checkpoint, early_stopping],\n",
    "#     logger=logger\n",
    "# )\n",
    "    \n",
    "# trainer.fit(model, train_datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.seq_encoder.learnable_attention_matrix.state_dict(), \"saved_models/coles_churn_learnable_attention_matrix.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pooling_model.learnable_attention_matrix.load_state_dict(torch.load(f\"saved_models/coles_default_learnable_attention_matrix.pth\"))\n",
    "pooling_model.learnable_attention_matrix.load_state_dict(torch.load(f\"saved_models/coles_churn_learnable_attention_matrix.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'learnable_attention'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooling_model.pooling_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, targets = embed_data(pooling_model, train + val, **cfg_validation[\"embed_data\"])\n",
    "N = len(embeddings)\n",
    "indices = np.arange(N)\n",
    "\n",
    "embeddings_test, targets_test = embed_data(\n",
    "    pooling_model,\n",
    "    test,\n",
    "    **cfg_validation[\"embed_data\"]\n",
    ")\n",
    "\n",
    "results = []\n",
    "for i in range(cfg_validation[\"n_runs\"]):\n",
    "\n",
    "    bootstrap_inds = np.random.choice(indices, size=N, replace=True)\n",
    "    embeddings_train, targets_train = embeddings[bootstrap_inds], targets[bootstrap_inds]\n",
    "\n",
    "    metrics = eval_embeddings(\n",
    "        embeddings_train,\n",
    "        targets_train,\n",
    "        embeddings_test,\n",
    "        targets_test,\n",
    "        cfg_validation[\"model\"]\n",
    "    )\n",
    "\n",
    "    results.append(metrics)\n",
    "\n",
    "res = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUROC</th>\n",
       "      <th>PR-AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.762683</td>\n",
       "      <td>0.803368</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.754209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.760319</td>\n",
       "      <td>0.809697</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.762376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.758363</td>\n",
       "      <td>0.814696</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.740368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.758428</td>\n",
       "      <td>0.813210</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.749186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.763025</td>\n",
       "      <td>0.811941</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.744898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.763547</td>\n",
       "      <td>0.819940</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.747440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.755331</td>\n",
       "      <td>0.813412</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.734899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.767084</td>\n",
       "      <td>0.827133</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.754266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.750864</td>\n",
       "      <td>0.807020</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.722973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.757091</td>\n",
       "      <td>0.802768</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.745704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AUROC    PR-AUC  Accuracy   F1Score\n",
       "0  0.762683  0.803368     0.708  0.754209\n",
       "1  0.760319  0.809697     0.712  0.762376\n",
       "2  0.758363  0.814696     0.690  0.740368\n",
       "3  0.758428  0.813210     0.692  0.749186\n",
       "4  0.763025  0.811941     0.700  0.744898\n",
       "5  0.763547  0.819940     0.704  0.747440\n",
       "6  0.755331  0.813412     0.684  0.734899\n",
       "7  0.767084  0.827133     0.712  0.754266\n",
       "8  0.750864  0.807020     0.672  0.722973\n",
       "9  0.757091  0.802768     0.704  0.745704"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUROC</th>\n",
       "      <th>PR-AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.759673</td>\n",
       "      <td>0.812318</td>\n",
       "      <td>0.697800</td>\n",
       "      <td>0.745632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.004679</td>\n",
       "      <td>0.007391</td>\n",
       "      <td>0.013079</td>\n",
       "      <td>0.011062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         AUROC    PR-AUC  Accuracy   F1Score\n",
       "mean  0.759673  0.812318  0.697800  0.745632\n",
       "std   0.004679  0.007391  0.013079  0.011062"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.agg([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
