{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "dir2 = os.path.abspath('')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path:\n",
    "    sys.path.append(dir1)\n",
    "\n",
    "os.chdir('..')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from hydra import initialize, compose\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "\n",
    "from ptls.preprocessing import PandasDataPreprocessor\n",
    "from ptls.frames import PtlsDataModule\n",
    "import ptls\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.coles import CustomColesDataset, CustomCoLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict\n",
    "\n",
    "from ptls.nn.seq_encoder.containers import SeqEncoderContainer\n",
    "from ptls.frames.coles import CoLESModule\n",
    "\n",
    "\n",
    "class CustomCoLES(CoLESModule):\n",
    "    \"\"\"\n",
    "    Custom coles module inhereted from ptls coles module.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        optimizer_partial: Callable,\n",
    "        lr_scheduler_partial: Callable,\n",
    "        sequence_encoder: SeqEncoderContainer,\n",
    "    ) -> None:\n",
    "        \"\"\"Overrided initialize method, which is suitable for our tasks\n",
    "\n",
    "        Args:\n",
    "            optimizer_partial (Callable): Partial initialized torch optimizer (with parameters)\n",
    "            lr_scheduler_partial (Callable): Partial initialized torch lr scheduler\n",
    "                (with parameters)\n",
    "            sequence_encoder (SeqEncoderContainer): Ptls sequence encoder\n",
    "                (including sequence encoder and single transaction encoder)\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            seq_encoder=sequence_encoder,\n",
    "            optimizer_partial=optimizer_partial,\n",
    "            lr_scheduler_partial=lr_scheduler_partial,\n",
    "        )\n",
    "        self.sequence_encoder_model = sequence_encoder\n",
    "\n",
    "    def get_seq_encoder_weights(self) -> Dict:\n",
    "        \"\"\"Get weights of the sequnce encoder in torch format\n",
    "\n",
    "        Returns:\n",
    "            dict: Encoder weights\n",
    "        \"\"\"\n",
    "        return self.sequence_encoder_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.coles.datamodule import SampleAll\n",
    "from ptls.frames.coles.split_strategy import AbsSplit, SampleSlices\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import minimum, maximum\n",
    "from ptls.data_load.padded_batch import PaddedBatch\n",
    "from itertools import chain\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from ptls.nn.seq_encoder.abs_seq_encoder import AbsSeqEncoder\n",
    "from ptls.frames import ABSModule\n",
    "\n",
    "\n",
    "class CoLESonCoLES(ABSModule):\n",
    "    \"\"\"\n",
    "    Coles on coles embeddings model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        optimizer_partial: Callable,\n",
    "        lr_scheduler_partial: Callable,\n",
    "        frozen_encoder: SeqEncoderContainer,\n",
    "        col_time: str = \"event_time\",\n",
    "        encoding_splitter: AbsSplit = SampleAll(20, 1),\n",
    "        training_splitter: AbsSplit = SampleSlices(split_count=5, cnt_max=150, cnt_min=15)\n",
    "    ) -> None:\n",
    "        \"\"\"Overrided initialize method, which is suitable for our tasks\n",
    "\n",
    "        Args:\n",
    "            optimizer_partial (Callable): Partial initialized torch optimizer (with parameters)\n",
    "            lr_scheduler_partial (Callable): Partial initialized torch lr scheduler\n",
    "                (with parameters)\n",
    "            sequence_encoder (SeqEncoderContainer): Ptls sequence encoder\n",
    "                (including sequence encoder and single transaction encoder)\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            sequence_encoder=None,\n",
    "            optimizer_partial=optimizer_partial,\n",
    "            lr_scheduler_partial=lr_scheduler_partial,\n",
    "        )\n",
    "        self.sequence_encoder_model = sequence_encoder\n",
    "        self.frozen_encoder = frozen_encoder\n",
    "        self.encoding_splitter = encoding_splitter\n",
    "        self.training_splitter = training_splitter\n",
    "        self.col_time = col_time\n",
    "\n",
    "    def _encode_and_split(self, x: PaddedBatch, y: torch.Tensor, step: int = 20):\n",
    "        dates = x.payload[self.col_time]   # (B, T)\n",
    "        dates_len = dates.shape[1]\n",
    "        start_pos = np.arange(0, dates_len - step, 1)\n",
    "\n",
    "        def encode():\n",
    "            for s in start_pos:\n",
    "                torch.cuda.empty_cache()\n",
    "                payload = {k: v[:, s : s + step] for k, v in x.payload.items()}\n",
    "                seq_lens = minimum(maximum(x.seq_lens - s, torch.zeros_like(x.seq_lens)), torch.full_like(x.seq_lens, step))\n",
    "                pb = PaddedBatch(payload, seq_lens)\n",
    "\n",
    "                yield self.frozen_encoder(pb).detach().cpu()\n",
    "\n",
    "        emb_sequences = torch.stack([*encode()], dim=1)\n",
    "\n",
    "        def split():\n",
    "            for i, elem in enumerate(emb_sequences):\n",
    "                indexes = self.training_splitter.split(dates)\n",
    "                yield [elem[ix] for ix in indexes], [y[i].item()] * len(indexes)\n",
    "\n",
    "        emb_sequences, extended_y = zip(*split())\n",
    "\n",
    "        emb_sequences = list(chain(*emb_sequences)) # B\n",
    "        emb_sequences = pad_sequence(emb_sequences, batch_first=True).to(x.device)\n",
    "\n",
    "        extended_y = torch.tensor(list(chain(*extended_y))).to(x.device)\n",
    "        \n",
    "        return PaddedBatch(payload=emb_sequences, length=x.seq_lens), extended_y\n",
    "    \n",
    "    def shared_step(self, x, y):\n",
    "        x, y = self._encode_and_split(x, y)\n",
    "        y_h = self.sequence_encoder(x)\n",
    "        if self._head is not None:\n",
    "            y_h = self._head(y_h)\n",
    "        return y_h, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(config_path=\"../config\", version_base=None):\n",
    "    cfg = compose(config_name=\"config_churn\")\n",
    "    \n",
    "cfg_preprop = cfg[\"dataset\"]\n",
    "cfg_model = cfg[\"model\"]\n",
    "cfg_model[\"trainer_coles\"][\"trainer\"][\"devices\"] = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>mcc_code</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>amount</th>\n",
       "      <th>global_target</th>\n",
       "      <th>holiday_target</th>\n",
       "      <th>weekend_target</th>\n",
       "      <th>churn_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>2017-10-21 00:00:00</td>\n",
       "      <td>5023.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-10-12 12:24:07</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-12-05 00:00:00</td>\n",
       "      <td>767.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-10-21 00:00:00</td>\n",
       "      <td>2031.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2017-10-24 13:14:24</td>\n",
       "      <td>36562.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-10-16 00:00:00</td>\n",
       "      <td>380.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-10-10 00:00:00</td>\n",
       "      <td>378.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-10-16 00:00:00</td>\n",
       "      <td>199.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-10-11 00:00:00</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-07-26 00:00:00</td>\n",
       "      <td>598.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  mcc_code           timestamp   amount  global_target  \\\n",
       "0        0        19 2017-10-21 00:00:00   5023.0              0   \n",
       "1        0         2 2017-10-12 12:24:07  20000.0              0   \n",
       "2        0        10 2017-12-05 00:00:00    767.0              0   \n",
       "3        0         1 2017-10-21 00:00:00   2031.0              0   \n",
       "4        0         9 2017-10-24 13:14:24  36562.0              0   \n",
       "5        1         3 2017-10-16 00:00:00    380.0              0   \n",
       "6        1         3 2017-10-10 00:00:00    378.0              0   \n",
       "7        1         3 2017-10-16 00:00:00    199.0              0   \n",
       "8        1         3 2017-10-11 00:00:00    400.0              0   \n",
       "9        1         1 2017-07-26 00:00:00    598.0              0   \n",
       "\n",
       "   holiday_target  weekend_target  churn_target  \n",
       "0               0               1             0  \n",
       "1               0               0             0  \n",
       "2               0               0             0  \n",
       "3               0               1             0  \n",
       "4               0               0             0  \n",
       "5               0               0             0  \n",
       "6               0               0             0  \n",
       "7               0               0             0  \n",
       "8               0               0             0  \n",
       "9               0               0             0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(Path(cfg[\"dataset\"][\"dir_path\"]).joinpath(cfg[\"dataset\"][\"train_file_name\"]))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = PandasDataPreprocessor(\n",
    "    col_id=\"user_id\",\n",
    "    col_event_time=\"timestamp\",\n",
    "    event_time_transformation=\"dt_to_timestamp\",\n",
    "    cols_category=[\"mcc_code\"],\n",
    "    cols_numerical=[\"amount\"],\n",
    "    return_records=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = preprocessor.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(dataset, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data: CustomColesDataset = instantiate(cfg_model[\"dataset\"], data=train, splitter = ptls.frames.coles.split_strategy.NoSplit())\n",
    "val_data: CustomColesDataset = instantiate(cfg_model[\"dataset\"], data=val, splitter=ptls.frames.coles.split_strategy.NoSplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule: PtlsDataModule = instantiate(\n",
    "    cfg_model[\"datamodule\"],\n",
    "    train_data=train_data,\n",
    "    valid_data=val_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = datamodule.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 20, 20, 20, 20,  0, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20,\n",
       "        20,  0, 20, 20, 20,  7, 20,  5, 20,  0, 20,  0, 20, 20,  0, 20, 20, 20,\n",
       "         0,  3, 20,  0, 20, 20, 20,  5, 20, 20,  0, 20, 20, 17, 20, 20, 20, 20,\n",
       "        12, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20,  0, 20, 20, 20, 14, 20, 20,\n",
       "        20,  0, 20, 20, 20, 20,  4, 20, 20, 20, 20, 20, 20, 20,  1, 20, 19, 20,\n",
       "        20,  0,  0, 20, 20, 20, 20, 20, 20,  0, 20,  6, 20, 20, 20, 20, 20, 20,\n",
       "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20,\n",
       "        20, 20])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 30\n",
    "step = 20\n",
    "torch.minimum(torch.maximum(b[0].seq_lens - s, torch.zeros_like(b[0].seq_lens)), torch.full_like(b[0].seq_lens, step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 23, 134, 113, 184,  69,  18,  66,  50, 159,  95, 118, 247, 307,  44,\n",
       "        101, 137,  67, 156, 117,  16, 159, 108, 104,  37, 107,  35,  64,  23,\n",
       "         65,  26, 107, 217,  20, 113, 118,  85,  30,  33,  64,  19, 202,  79,\n",
       "        225,  35, 118, 330,  18, 126, 178,  47, 121, 127, 106,  64,  42,  47,\n",
       "        196, 145, 135, 135,  56, 144,  66,  69, 108,  19, 105, 131, 127,  44,\n",
       "        190, 139,  98,  17,  81, 194,  74,  83,  34, 202, 173,  72, 109, 186,\n",
       "        200, 140,  31,  91,  49,  85, 181,  23,  15,  86, 143,  75,  56,  93,\n",
       "         52,  29,  65,  36, 201, 146, 202, 150, 107, 113, 272, 203, 128, 115,\n",
       "        173,  70, 149,  95, 133, 319,  61,  62, 123, 157,  46, 173, 204,  68,\n",
       "        124,  73])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0].seq_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 330])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0].payload['global_target'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def is_seq_feature(k: str, x):\n",
    "    \"\"\"Check is value sequential feature\n",
    "    Synchronized with ptls.data_load.padded_batch.PaddedBatch.is_seq_feature\n",
    "\n",
    "    Iterables are:\n",
    "        np.array\n",
    "        torch.Tensor\n",
    "\n",
    "    Not iterable:\n",
    "        list    - dont supports indexing\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    k:\n",
    "        feature_name\n",
    "    x:\n",
    "        value for check\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        True if value is iterable\n",
    "    \"\"\"\n",
    "    if k == 'event_time':\n",
    "        return True\n",
    "    if k.startswith('target'):\n",
    "        return False\n",
    "    if type(x) in (np.ndarray, torch.Tensor):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model: CustomCoLES = instantiate(cfg_model[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['global_target', 'holiday_target', 'weekend_target', 'churn_target', 'event_time', 'mcc_code', 'amount'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0].payload.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_target True\n",
      "holiday_target True\n",
      "weekend_target True\n",
      "churn_target True\n",
      "event_time True\n",
      "mcc_code True\n",
      "amount True\n"
     ]
    }
   ],
   "source": [
    "for k, v in b[0].payload.items():\n",
    "    print(k, is_seq_feature(k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.stack([model(b[0]) for _ in range(2)], dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a():\n",
    "    yield 1, 2\n",
    "    yield 3, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, d = zip(*a())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "seq_encoder = model.seq_encoder.to(\"cuda:0\")\n",
    "\n",
    "optimizer = partial(torch.optim.Adam, lr=0.004)\n",
    "lr_scheduler = partial(torch.optim.lr_scheduler.ReduceLROnPlateau, factor=0.902, patience=2)\n",
    "mdl = CoLESonCoLES(optimizer, lr_scheduler, model.seq_encoder, model.seq_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b[0].to(\"cuda:0\"), b[1].to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Embedding...\n",
      "Finished embeddings...\n"
     ]
    }
   ],
   "source": [
    "x, y = mdl._encode_and_split(*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   0,   0,   0,   0,   1,   1,   1,   1,   1,   2,   2,   2,   2,\n",
       "          2,   3,   3,   3,   3,   3,   4,   4,   4,   4,   4,   5,   5,   5,\n",
       "          5,   5,   6,   6,   6,   6,   6,   7,   7,   7,   7,   7,   8,   8,\n",
       "          8,   8,   8,   9,   9,   9,   9,   9,  10,  10,  10,  10,  10,  11,\n",
       "         11,  11,  11,  11,  12,  12,  12,  12,  12,  13,  13,  13,  13,  13,\n",
       "         14,  14,  14,  14,  14,  15,  15,  15,  15,  15,  16,  16,  16,  16,\n",
       "         16,  17,  17,  17,  17,  17,  18,  18,  18,  18,  18,  19,  19,  19,\n",
       "         19,  19,  20,  20,  20,  20,  20,  21,  21,  21,  21,  21,  22,  22,\n",
       "         22,  22,  22,  23,  23,  23,  23,  23,  24,  24,  24,  24,  24,  25,\n",
       "         25,  25,  25,  25,  26,  26,  26,  26,  26,  27,  27,  27,  27,  27,\n",
       "         28,  28,  28,  28,  28,  29,  29,  29,  29,  29,  30,  30,  30,  30,\n",
       "         30,  31,  31,  31,  31,  31,  32,  32,  32,  32,  32,  33,  33,  33,\n",
       "         33,  33,  34,  34,  34,  34,  34,  35,  35,  35,  35,  35,  36,  36,\n",
       "         36,  36,  36,  37,  37,  37,  37,  37,  38,  38,  38,  38,  38,  39,\n",
       "         39,  39,  39,  39,  40,  40,  40,  40,  40,  41,  41,  41,  41,  41,\n",
       "         42,  42,  42,  42,  42,  43,  43,  43,  43,  43,  44,  44,  44,  44,\n",
       "         44,  45,  45,  45,  45,  45,  46,  46,  46,  46,  46,  47,  47,  47,\n",
       "         47,  47,  48,  48,  48,  48,  48,  49,  49,  49,  49,  49,  50,  50,\n",
       "         50,  50,  50,  51,  51,  51,  51,  51,  52,  52,  52,  52,  52,  53,\n",
       "         53,  53,  53,  53,  54,  54,  54,  54,  54,  55,  55,  55,  55,  55,\n",
       "         56,  56,  56,  56,  56,  57,  57,  57,  57,  57,  58,  58,  58,  58,\n",
       "         58,  59,  59,  59,  59,  59,  60,  60,  60,  60,  60,  61,  61,  61,\n",
       "         61,  61,  62,  62,  62,  62,  62,  63,  63,  63,  63,  63,  64,  64,\n",
       "         64,  64,  64,  65,  65,  65,  65,  65,  66,  66,  66,  66,  66,  67,\n",
       "         67,  67,  67,  67,  68,  68,  68,  68,  68,  69,  69,  69,  69,  69,\n",
       "         70,  70,  70,  70,  70,  71,  71,  71,  71,  71,  72,  72,  72,  72,\n",
       "         72,  73,  73,  73,  73,  73,  74,  74,  74,  74,  74,  75,  75,  75,\n",
       "         75,  75,  76,  76,  76,  76,  76,  77,  77,  77,  77,  77,  78,  78,\n",
       "         78,  78,  78,  79,  79,  79,  79,  79,  80,  80,  80,  80,  80,  81,\n",
       "         81,  81,  81,  81,  82,  82,  82,  82,  82,  83,  83,  83,  83,  83,\n",
       "         84,  84,  84,  84,  84,  85,  85,  85,  85,  85,  86,  86,  86,  86,\n",
       "         86,  87,  87,  87,  87,  87,  88,  88,  88,  88,  88,  89,  89,  89,\n",
       "         89,  89,  90,  90,  90,  90,  90,  91,  91,  91,  91,  91,  92,  92,\n",
       "         92,  92,  92,  93,  93,  93,  93,  93,  94,  94,  94,  94,  94,  95,\n",
       "         95,  95,  95,  95,  96,  96,  96,  96,  96,  97,  97,  97,  97,  97,\n",
       "         98,  98,  98,  98,  98,  99,  99,  99,  99,  99, 100, 100, 100, 100,\n",
       "        100, 101, 101, 101, 101, 101, 102, 102, 102, 102, 102, 103, 103, 103,\n",
       "        103, 103, 104, 104, 104, 104, 104, 105, 105, 105, 105, 105, 106, 106,\n",
       "        106, 106, 106, 107, 107, 107, 107, 107, 108, 108, 108, 108, 108, 109,\n",
       "        109, 109, 109, 109, 110, 110, 110, 110, 110, 111, 111, 111, 111, 111,\n",
       "        112, 112, 112, 112, 112, 113, 113, 113, 113, 113, 114, 114, 114, 114,\n",
       "        114, 115, 115, 115, 115, 115, 116, 116, 116, 116, 116, 117, 117, 117,\n",
       "        117, 117, 118, 118, 118, 118, 118, 119, 119, 119, 119, 119, 120, 120,\n",
       "        120, 120, 120, 121, 121, 121, 121, 121, 122, 122, 122, 122, 122, 123,\n",
       "        123, 123, 123, 123, 124, 124, 124, 124, 124, 125, 125, 125, 125, 125,\n",
       "        126, 126, 126, 126, 126, 127, 127, 127, 127, 127])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Oct  4 19:29:14 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.48.07    Driver Version: 515.48.07    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:3B:00.0 Off |                  N/A |\n",
      "| 73%   61C    P2    86W / 170W |   4593MiB / 12288MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:5E:00.0 Off |                  N/A |\n",
      "| 57%   56C    P2   137W / 170W |  11976MiB / 12288MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
